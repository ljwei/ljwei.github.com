<!doctype html>
<html class="theme-next use-motion theme-next-mist">
<head>
  

<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






  <link rel="stylesheet" type="text/css" href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5"/>


<link rel="stylesheet" type="text/css" href="/css/main.css?v=0.4.3"/>


    <meta name="description" content="machine learning | python | ai | math" />



  <meta name="keywords" content="machine learning," />





  <link rel="shorticon icon" type="image/x-icon" href="/favicon.ico?v=0.4.3" />



<script type="text/javascript" id="hexo.configuration">
  var CONFIG = {
    scheme: 'Mist',
    analytics: {
      google: ''
    },
    sidebar: 'post'
  };
</script>




  <title> 机器学习理论 // Jerry's BLOG </title>
</head>

<body>
<!--[if lte IE 8]> <div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;margin:0 auto;'> <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode"><img src="http://7u2nvr.com1.z0.glb.clouddn.com/picouterie.jpg" border="0" height="42" width="820" alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today or use other browser ,like chrome firefox safari." style='margin-left:auto;margin-right:auto;display: block;'/></a></div> <![endif]-->
  <div class="container one-column page-post-detail">
    <div class="headband"></div>

    <div id="header" class="header">
      <div class="header-inner">
        <h1 class="site-meta">
  <span class="logo-line-before"><i></i></span>
  <a href="/" class="brand">
      <span class="logo">
        <i class="icon-logo"></i>
      </span>
      <span class="site-title">Jerry's BLOG</span>
  </a>
  <span class="logo-line-after"><i></i></span>
</h1>


  <ul id="menu" class="menu">
     
    
      
      <li class="menu-item menu-item-home">
        <a href="/">
          <i class="menu-item-icon icon-home"></i> <br />
          首页
        </a>
      </li>
    
      
      <li class="menu-item menu-item-categories">
        <a href="/categories">
          <i class="menu-item-icon icon-categories"></i> <br />
          分类
        </a>
      </li>
    
      
      <li class="menu-item menu-item-archives">
        <a href="/archives">
          <i class="menu-item-icon icon-archives"></i> <br />
          归档
        </a>
      </li>
    
      
      <li class="menu-item menu-item-tags">
        <a href="/tags">
          <i class="menu-item-icon icon-tags"></i> <br />
          标签
        </a>
      </li>
    
  </ul>


      </div>
    </div>

    <div id="main" class="main">
      <div class="main-inner">
        <div id="content" class="content">
          

  <div id="posts" class="posts-expand">
    

  <div class="post post-type-normal ">
    <div class="post-header">

      
      
        <h1 class="post-title">
          
          
            
              机器学习理论
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于 2016-04-03
        </span>

        
          <span class="post-category">
            &nbsp; | &nbsp; 分类于
            
              <a href="/categories/machine-learning/">machine learning</a>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
            &nbsp; | &nbsp;
            <a href="/2016/04/03/machine-learning/machine-learning-theory/统计学习基础/#comments" >
              <span class="post-comments-count ds-thread-count" data-thread-key="2016/04/03/machine-learning/machine-learning-theory/统计学习基础/"></span>
            </a>
          </span>
          
        
      </div>
    </div>

    <div class="post-body">

      
      

      
        <p>[toc]</p>
<p>机器学习虽然涉及的知识点很多，但是在应用机器学习时，有一些共同的问题需要考虑，这也构成了机器学习的基础理论。先了解机器学习的一些共性问题和基础理论，对于理解机器学习有很大的帮助。<br><a id="more"></a></p>
<h1 id="机器学习定义">机器学习定义</h1><p>一种经常引用的英文定义是：A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.</p>
<h1 id="基本概念">基本概念</h1><p>上面的这段机器学习的定义中，提到了很多机器学习中很重要的概念，下面简单解释。</p>
<p><strong>输入空间</strong>：输入的所有可能值的集合。<br><strong>输出空间</strong>：输出的所有可能值的集合。<br><strong>特征空间</strong>：在很多机器学习的任务中，并不是直接对输入空间中的原数据格式进行处理，而是先抽取出更高层的特征，这些特征会组成一个向量，叫特征向量，而特征向量存在的空间就是特征空间。特征空间中的每一维都对于一个特征。<br><strong>假设空间</strong>：机器学习的目的在于建立从输入到输出的映射，这个映射所构成的集合，称为假设空间。</p>
<h1 id="机器学习的步骤">机器学习的步骤</h1><p>一个完整实现机器学习的步骤如下：</p>
<p>1 构造训练集<br>2 确定要使用的模型<br>3 确定模型选择的标准<br>4 实现求解最优模型的算法<br>5 训练<br>6 预测</p>
<p>从这个过程可以看出，最关键的步骤在于2、3、4，在《统计学习方法》中被称为模型、策略和算法，合称统计学习三要素。</p>
<h1 id="三要素">三要素</h1><p>在《统计学习方法》中，一个方法可以表示如下：</p>
<p>$$<br>方法＝模型+策略+算法<br>$$</p>
<p>但是，一种更为直观的表述是：</p>
<p>$$<br>机器学习＝表示+评价+优化<br>$$</p>
<p>遵循这一思路来重新理解统计学习的一些算法，能更快更准确的抓住算法的本质。下面以监督学习为例来说明。</p>
<p>在统计学习中，模型是至关重要的。根据模型的不同可以将方法分为两大类，分别是：概率模型和非概率模型。将由决策函数表示的模型为非概率模型，而将由条件概率表示的模型称为概率模型。这里中不同的模型决定了不同的形式的策略和算法，下面以监督学习为例，分别进行说明。</p>
<h2 id="非概率模型的三要素">非概率模型的三要素</h2><h3 id="模型">模型</h3><p>在监督学习过程中，模型就是所要学习的决策函数。模型的假设空间包含所有可能的决策函数。假设空间用H表示：<br>$$<br>H={f|Y=f_\theta(X),\theta\in R^n}<br>$$<br>其中，X和Y是定义在输入空间的和输出空间的变量。参数向量$\theta$的取值空间称为参数空间。</p>
<h3 id="策略">策略</h3><p>有了模型的假设空间，统计学习接着需要考虑的是按照什么样的准则学习或选择最优模型。统计学习的目标在于从假设空间中选取最优模型。如何选取最优呢？首先需要定义什么才是好的模型，于是引出了损失函数（代价函数）的概念。</p>
<h4 id="损失函数">损失函数</h4><p>损失函数用来度量模型一次预测的好坏。给定一个输入X，模型的预测结果f(X)和真实输出Y之间的距离，一般用$L(Y,f(X))$来表示，有很多中方法来衡量，包括：</p>
<ul>
<li>0-1损失函数</li>
<li>绝对损失函数</li>
<li>平方损失函数</li>
</ul>
<p>不同的损失函数有不同的效果，都有其应用的场景。</p>
<h4 id="风险函数">风险函数</h4><p>有了损失函数，那么进一步，就可以定义整个模型预测的好坏了，风险函数（或期望损失）就是用来定义平均意义下模型预测的好坏。可以表示如下：</p>
<p>$$<br>R_{exp}(f)=E[L(Y,f(X))]=\int{L(y,f(x))P(x,y)dxdy}<br>$$</p>
<p>学习的目标就是选择期望风险最小的模型，但是由于联合分布P(X,Y)是未知的，因此不能直接计算。</p>
<p>$$<br>R<em>{emp}(f)=\frac{1}{N}\sum</em>{i=1}^NL(y_i,f(x_i))<br>$$</p>
<p>经验风险是模型关于训练样本的平均损失。根据大数定理，当样本容量N趋于无穷时，经验风险趋近于期望风险。因此，一般用经验风险来近似。但是现实中训练样本数量有限，很容易导致过拟合，一般会加上表示模型复杂度的正则化项，这就是结构风险：</p>
<p>$$<br>R<em>{srm}(f)=\frac{1}{N}\sum</em>{i=1}^NL(y_i,f(x_i))+\lambda J(f)<br>$$</p>
<p>采用不同的风险函数去逼近，就会有不同的效果，这就涉及到监督学习中的两个基本策略：经验风险最小化和结构风险最小化。</p>
<h4 id="经验风险最小化和结构风险最小化">经验风险最小化和结构风险最小化</h4><p>按照经验风险最小化的原则，求最优模型就是求解如下最优化问题：</p>
<p>$$<br>min\frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))<br>$$<br>当样本容量足够大时，经验风险最小化能保证有很好的学习效果。当样本小时，容易过拟合。</p>
<p>按照结构风险最小化原则，求最优模型就是求解如下最优化问题：</p>
<p>$$<br>min\frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))+\lambda J(f)<br>$$</p>
<p>通过这两种策略，监督学习问题就转变成了最优化问题，下面就要用到最优化的知识来求解这些问题了。</p>
<h3 id="算法">算法</h3><p>算法是指学习模型的具体计算方法。根据问题的不同，求解的方法也不同，有的简单的模型，直接有解析解，比如线性回归，可以直接用最小二乘法求解，而对于大多数问题，需要采用一些迭代优化算法。关于这些优化算法，在下一篇文章中专门介绍。</p>
<h2 id="概率模型的三要素">概率模型的三要素</h2><h3 id="模型-1">模型</h3><p>在概率模型中，模型就是所要学习的条件概率分布，而模型的假设空间就是所有可能的条件概率分布。</p>
<p>$$<br>F={P|P_\theta(Y|X),\theta\in R^n}<br>$$</p>
<p>其中，X和Y是定义在输入和输出空间的随机变量。</p>
<h3 id="参数估计">参数估计</h3><p>在概率模型中，一般不用损失函数或风险函数来表示，而是参数估计。</p>
<p>参数估计是数理统计学中的重要内容,参数估计（parameter estimation）是根据从总体中抽取的样本估计总体分布中包含的未知参数的方法。人们常常需要根据手中的数据，分析或推断数据反映的本质规律。即根据样本数据如何选择统计量去推断总体的分布或数字特征等。统计推断是数理统计研究的核心问题。所谓统计推断是指根据样本对总体分布或分布的数字特征等作出合理的推断。它是统计推断的一种基本形式，是数理统计学的一个重要分支，分为点估计和区间估计两部分。</p>
<p>在统计学习的很多算法中,都需要对参数进行估计,其中一般都是进行点估计.</p>
<p>点估计是依据样本估计总体分布中所含的未知参数或未知参数的函数。通常它们是总体的某个特征值，如数学期望、方差和相关系数等。点估计问题就是要构造一个只依赖于样本的量，作为未知参数或未知参数的函数的估计值。例如，设一批产品的废品率为θ。为估计θ，从这批产品中随机地抽出n个作检查，以X记其中的废品个数，用X/n估计θ，这就是一个点估计。构造点估计常用的方法是：</p>
<ul>
<li>矩估计法。用样本矩估计总体矩，如用样本均值估计总体均值。</li>
<li>最大似然估计法。基于频率学派的观点而提出的估计法。</li>
<li>最小二乘法。主要用于线性统计模型中的参数估计问题。</li>
<li>贝叶斯估计法。基于贝叶斯学派的观点而提出的估计法。</li>
</ul>
<p>其中又以最大似然估计和贝叶斯估计应用最为广泛,这两种方法被别根据频率学派和贝叶斯学派的观点而来,介于这两种方法之间,还有一种最大后验估计.</p>
<h4 id="最大似然估计">最大似然估计</h4><p>极大似然估计和贝叶斯估计分别代表了频率派和贝叶斯派的观点。频率派认为，参数是客观存在的，只是未知而已。因此，频率派最关心极大似然函数：</p>
<p>$$<br>L(\theta|X)=p(X|\theta)=\prod_{x \in X} p(X=x|\theta)<br>$$</p>
<p>极大似然估计如下所示:</p>
<p>$$<br>\theta<em>{MLE}=argmax</em>\theta \log L(\theta|X)=argmax<em>\theta \sum</em>{x \in X} log p(x|\theta)<br>$$</p>
<h4 id="最大后验估计">最大后验估计</h4><p>根据贝叶斯公式我们有：</p>
<p>$$p(\theta|X)=\frac{p(X|\theta)p(\theta)}{p(X)}=\frac{p(X|\theta)p(\theta)}{\int{p(X|\theta)p(\theta)d\theta}}$$</p>
<p>最大后验估计与最大似然估计相似，不同点在于估计的函数中允许加入一个先验，也就是说此时不是要求似然函数最大，而是要求由贝叶斯公式计算出的整个后验概率最大，即</p>
<p>$$<br>\theta<em>{MAP}=argmax</em>\theta p(X|\theta)p(\theta)<br>$$</p>
<p>最大后验概率和极大似然估计很像，只是多了一项先验分布，它体现了贝叶斯认为参数也是随机变量的观点，在实际运算中通常通过超参数给出先验分布。</p>
<h4 id="贝叶斯估计">贝叶斯估计</h4><p>相反的，贝叶斯派认为参数也是随机的，和一般随机变量没有本质区别，正是因为参数不能固定，当给定一个输入x后，我们不能用一个确定的y表示输出结果，必须用一个概率的方式表达出来，所以贝叶斯学派的预测值是一个期望值，如下所示：</p>
<p>$$<br>E[y|x,X]=\int{p(y|x, \theta)p(\theta|X)X\theta}<br>$$</p>
<p>该公式称为全贝叶斯预测。现在的问题是如何求$p(\theta|X)$（后验概率），</p>
<p>可惜的是，上面的后验概率通常是很难计算的，因为要对所有的参数进行积分，不能找到一个典型的闭合解（解析解）。</p>
<p>从以上可以看出，一方面，极大似然估计和最大后验概率都是参数的点估计。在频率学派中，参数固定了，预测值也就固定了。最大后验概率是贝叶斯学派的一种近似手段，因为完全贝叶斯估计不一定可行。另一方面，最大后验概率可以看作是对先验和MLE的一种折衷，如果数据量足够大，最大后验概率和最大似然估计趋向于一致，如果数据为0,最大后验仅由先验决定。</p>
<p>更详细的推倒过程,可以参考<a href="http://blog.csdn.net/yangliuy/article/details/8296481" target="_blank" rel="external">这篇文章</a>.</p>
<h2 id="概率模型和非概率模型的关系">概率模型和非概率模型的关系</h2><p>虽然前面提到了在概率模型和非概率模型中，有不同的模型表示，不同的学习策略，但是其实两者是统一的。对于极大似然估计：</p>
<p>$$<br>\theta<em>{MLE}=argmax</em>\theta \sum<em>{x \in X} log p(x|\theta)\=min\sum</em>{x \in X} -log p(x|\theta)<br>$$</p>
<p>因此可以认为，极大似然估计等价于经验风险最小化，损失函数可以看作对数损失函数。</p>
<p>同样的，对于最大后验概率估计：</p>
<p>$$<br>\theta<em>{MAP}=argmax</em>\theta \log p(X|\theta)p(\theta) \=argmax<em>\theta {\log L(X|\theta) + \log p(\theta)} \<br>=min{\sum</em>{x \in X} -log p(x|\theta)- \log p(\theta)}<br>$$</p>
<p>因此可以认为，最大后验概率估计等价于结构风险最小化，其中损失函数是对数损失函数，模型的复杂度有模型的先验概率表示。        </p>
<h1 id="模型选择">模型选择</h1><p>学习的目的是找到一个模型，不仅对训练集中的数据而且对未知的数据有很好的预测能力。但是模型的测试误差是没法直接知道的，我们只能通过模型的训练误差去近视，找到训练误差最小的，但是如果过于在乎减少训练误差，又会出现过拟合。因此，常常需要一些手段来帮助我们从中选出最接近真实模型的模型。</p>
<p>常见用来克服过拟合，帮助进行模型选择的方法有两个：正则化和交叉验证。</p>
<h2 id="正则化">正则化</h2><p>正则化是最典型的用来解决过拟合问题的方法。一般是在优化目标中，增加一个和模型复杂度相关的项，来限制模型复杂度过大。常见的正则化项是模型参数向量的范数。</p>
<ul>
<li>L0范数：向量中非零元素的个数</li>
<li>L1范数：绝对值之和</li>
<li>L2范数：欧几里得范数</li>
</ul>
<p>采用不同的范数可以达到不同的效果，但是为了优化方便，一般会采用L2范数。</p>
<h2 id="交叉验证">交叉验证</h2><p>在训练数据充足的情况下，进行模型选择的一种简单方法是随机将数据集分成三份：训练集、验证集、测试集。</p>
<p>但是在很多实际应用中，数据都是相对不充分的。为了更好地选择模型，会采用交叉验证的方法。</p>
<h3 id="hold-out">hold-out</h3><p>随机将数据分成两部分：训练集和测试集。直接用测试集来选择模型。</p>
<h3 id="S-fold">S-fold</h3><p>应用最多的一种交叉验证方法，首先随机将数据切分成S个互不相交的大小相同的子集。利用S-1个子集中的数据进行训练，利用剩下的来测试模型。重复S次，选出平均情况下最好的。</p>
<h3 id="leave-one-out">leave-one-out</h3><p>s-fold的一种特殊情况，此时S等于样本数，在数据极度缺乏的情况下使用。</p>
<h1 id="泛化能力">泛化能力</h1><h2 id="偏差-方差分解">偏差-方差分解</h2><h2 id="VC维">VC维</h2><h1 id="参考文献">参考文献</h1><ol>
<li><a href="https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0" target="_blank" rel="external">机器学习-维基百科</a></li>
<li>统计学习方法-李航</li>
<li><a href="http://www.valleytalk.org/wp-content/uploads/2012/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%82%A3%E4%BA%9B%E4%BA%8B.pdf" target="_blank" rel="external">机器学习那些事-刘知远</a></li>
<li>机器学习-周志华</li>
</ol>

      
    </div>

    <div class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/machine-learning/"> #machine learning </a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/04/03/machine-learning/机器学习概览/">机器学习概览</a>
            
          </div>

          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/04/01/设计模式/">设计模式</a>
            
          </div>
        </div>
      

      
      
    </div>
  </div>



    
      <div class="comments" id="comments">
        
          <div class="ds-thread" data-thread-key="2016/04/03/machine-learning/machine-learning-theory/统计学习基础/"
               data-title="机器学习理论" data-url="/2016/04/03/machine-learning/machine-learning-theory/统计学习基础/">
          </div>
        
      </div>
    
  </div>


        </div>

        
      </div>


      
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <div id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview">
        <div class="site-author motion-element">
          <img class="site-author-image" src="/avatar.jpg" alt="Jerry" />
          <p class="site-author-name">Jerry</p>
        </div>
        <p class="site-description motion-element">machine learning | python | ai | math</p>
        <div class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">41</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          <div class="site-state-item site-state-categories">
            <a href="/categories">
              <span class="site-state-item-count">10</span>
              <span class="site-state-item-name">分类</span>
              </a>
          </div>

          <div class="site-state-item site-state-tags">
            <a href="/tags">
              <span class="site-state-item-count">45</span>
              <span class="site-state-item-name">标签</span>
              </a>
          </div>

        </div>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

      </div>

      
        <div class="post-toc-wrap sidebar-panel-active">
          <div class="post-toc-indicator-top post-toc-indicator"></div>
          <div class="post-toc">
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#机器学习定义"><span class="nav-number">1.</span> <span class="nav-text">机器学习定义</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#基本概念"><span class="nav-number">2.</span> <span class="nav-text">基本概念</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#机器学习的步骤"><span class="nav-number">3.</span> <span class="nav-text">机器学习的步骤</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#三要素"><span class="nav-number">4.</span> <span class="nav-text">三要素</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#非概率模型的三要素"><span class="nav-number">4.1.</span> <span class="nav-text">非概率模型的三要素</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#模型"><span class="nav-number">4.1.1.</span> <span class="nav-text">模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#策略"><span class="nav-number">4.1.2.</span> <span class="nav-text">策略</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#损失函数"><span class="nav-number">4.1.2.1.</span> <span class="nav-text">损失函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#风险函数"><span class="nav-number">4.1.2.2.</span> <span class="nav-text">风险函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#经验风险最小化和结构风险最小化"><span class="nav-number">4.1.2.3.</span> <span class="nav-text">经验风险最小化和结构风险最小化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#算法"><span class="nav-number">4.1.3.</span> <span class="nav-text">算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#概率模型的三要素"><span class="nav-number">4.2.</span> <span class="nav-text">概率模型的三要素</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#模型-1"><span class="nav-number">4.2.1.</span> <span class="nav-text">模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#参数估计"><span class="nav-number">4.2.2.</span> <span class="nav-text">参数估计</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#最大似然估计"><span class="nav-number">4.2.2.1.</span> <span class="nav-text">最大似然估计</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#最大后验估计"><span class="nav-number">4.2.2.2.</span> <span class="nav-text">最大后验估计</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#贝叶斯估计"><span class="nav-number">4.2.2.3.</span> <span class="nav-text">贝叶斯估计</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#概率模型和非概率模型的关系"><span class="nav-number">4.3.</span> <span class="nav-text">概率模型和非概率模型的关系</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#模型选择"><span class="nav-number">5.</span> <span class="nav-text">模型选择</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#正则化"><span class="nav-number">5.1.</span> <span class="nav-text">正则化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#交叉验证"><span class="nav-number">5.2.</span> <span class="nav-text">交叉验证</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#hold-out"><span class="nav-number">5.2.1.</span> <span class="nav-text">hold-out</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#S-fold"><span class="nav-number">5.2.2.</span> <span class="nav-text">S-fold</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#leave-one-out"><span class="nav-number">5.2.3.</span> <span class="nav-text">leave-one-out</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#泛化能力"><span class="nav-number">6.</span> <span class="nav-text">泛化能力</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#偏差-方差分解"><span class="nav-number">6.1.</span> <span class="nav-text">偏差-方差分解</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#VC维"><span class="nav-number">6.2.</span> <span class="nav-text">VC维</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#参考文献"><span class="nav-number">7.</span> <span class="nav-text">参考文献</span></a></li></ol></div>
            
          </div>
          <div class="post-toc-indicator-bottom post-toc-indicator"></div>
        </div>
      

    </div>
  </div>


    </div>

    <div id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; &nbsp; 
  2016
  <span class="with-love">
    <i class="icon-heart"></i>
  </span>
  <span class="author">Jerry</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>



      </div>
    </div>

    <div class="back-to-top"></div>
  </div>

  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/fancy-box.js"></script>


  <script type="text/javascript" src="/js/helpers.js"></script>
  

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/js/motion_global.js" id="motion.global"></script>




  
  
<script type="text/javascript" src="/js/bootstrap.scrollspy.js" id="bootstrap.scrollspy.custom"></script>


<script type="text/javascript" id="sidebar.toc.highlight">
  $(document).ready(function () {
    var tocSelector = '.post-toc';
    var $tocSelector = $(tocSelector);
    var activeCurrentSelector = '.active-current';

    $tocSelector
      .on('activate.bs.scrollspy', function () {
        var $currentActiveElement = $(tocSelector + ' .active').last();

        removeCurrentActiveClass();
        $currentActiveElement.addClass('active-current');

        $tocSelector[0].scrollTop = $currentActiveElement.position().top;
      })
      .on('clear.bs.scrollspy', function () {
        removeCurrentActiveClass();
      });

    function removeCurrentActiveClass () {
      $(tocSelector + ' ' + activeCurrentSelector)
        .removeClass(activeCurrentSelector.substring(1));
    }

    function processTOC () {
      getTOCMaxHeight();
      toggleTOCOverflowIndicators();
    }

    function getTOCMaxHeight () {
      var $sidebarInner = $('.sidebar-inner');
      var height = $('.sidebar').height() -
                   $tocSelector.position().top -
                   $('.post-toc-indicator-bottom').height();

      $tocSelector.css('height', height);

      return height;
    }

    function toggleTOCOverflowIndicators () {
      tocOverflowIndicator(
        '.post-toc-indicator-top',
        $tocSelector.scrollTop() > 0 ? 'show' : 'hide'
      );

      tocOverflowIndicator(
        '.post-toc-indicator-bottom',
        $tocSelector.scrollTop() >= $tocSelector.find('ol').height() - $tocSelector.height() ? 'hide' : 'show'
      )
    }

    $(document).on('sidebar.didShow', function () {
      processTOC();
    });

    $('body').scrollspy({ target: tocSelector });
    $(window).on('resize', function () {
      if ( $('.sidebar').hasClass('sidebar-active') ) {
        processTOC();
      }
    });

    onScroll($tocSelector);

    function onScroll (element) {
      element.on('mousewheel DOMMouseScroll', function (event) {
          var oe = event.originalEvent;
          var delta = oe.wheelDelta || -oe.detail;
          var self = this;

          this.scrollTop += ( delta < 0 ? 1 : -1 ) * 30;
          event.preventDefault();

          toggleTOCOverflowIndicators();
      });
    }

    function tocOverflowIndicator (indicator, action) {
      $(indicator).velocity('stop').velocity({
        opacity: action === 'show' ? 0.4 : 0
      }, { duration: 100 });
    }

  });
</script>


  <script type="text/javascript" id="sidebar.nav">
    $(document).ready(function () {
      var html = $('html');

      $('.sidebar-nav li').on('click', function () {
        var item = $(this);
        var activeTabClassName = 'sidebar-nav-active';
        var activePanelClassName = 'sidebar-panel-active';
        if (item.hasClass(activeTabClassName)) {
          return;
        }

        var currentTarget = $('.' + activePanelClassName);
        var target = $('.' + item.data('target'));

        currentTarget.velocity('transition.slideUpOut', 200, function () {
          target
            .velocity('stop')
            .velocity('transition.slideDownIn', 200)
            .addClass(activePanelClassName);
        });

        item.siblings().removeClass(activeTabClassName);
        item.addClass(activeTabClassName);
      });

      $('.post-toc a').on('click', function (e) {
        e.preventDefault();
        var offset = $(escapeSelector(this.getAttribute('href'))).offset().top;
        html.velocity('stop').velocity('scroll', {
          offset: offset  + 'px',
          mobileHA: false
        });
      });

      // Expand sidebar on post detail page by default, when post has a toc.
      var $tocContent = $('.post-toc-content');
      if (isDesktop() && CONFIG.sidebar === 'post') {
        if ($tocContent.length > 0 && $tocContent.html().trim().length > 0) {
          displaySidebar();
        }
      }
    });
  </script>




  <script type="text/javascript">
    $(document).ready(function () {
      if (CONFIG.sidebar === 'always') {
        displaySidebar();
      }
    });
  </script>

  

  
  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"jw-ml"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  


  
  

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</body>
</html>
